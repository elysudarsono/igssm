{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 4: Tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This assignment is in two parts:\n",
    "\n",
    "* Linear regression implementation in Tensorflow\n",
    "* Dataset preparation for neural network model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Linear regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the linear regression algorithm as an exercise for implementing in Tensorflow.\n",
    "\n",
    "Recall the linear regression problem setting:\n",
    "\n",
    "Given a number of independent variables $x_i$, $i=1,\\ldots ,N$, we construct the matrix $\\mathbf{A}\\in\\mathbb{R}^{m\\times(N+1)}$, where the data on the independent variables is stored in rows of $\\mathbf{A}$, and the last column is filled with ones (to account for the bias term). Also let $\\mathbf{y}\\in\\mathbb{R}^m$ be the target values from the dataset.\n",
    "\n",
    "Then the linear regression problem can be expressed as\n",
    "$$\\mathbf{\\theta} = \\text{argmin} \\left|\\left|\\mathbf{A\\theta} - \\mathbf{y}\\right|\\right|_2^2$$\n",
    "\n",
    "where $\\mathbf{\\theta}\\in\\mathbb{R}^{N+1}$ contains the $N$ coefficients for each independent variable, followed by the bias term.\n",
    "\n",
    "Provided the columns of $\\mathbf{A}$ are linearly independent, the solution can be expressed in closed form as the normal equation:\n",
    "\n",
    "$$\\mathbf{\\theta} = (\\mathbf{A}^T \\mathbf{A})^{-1}\\mathbf{A}^T\\mathbf{y}.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Load the dataset in the file `poverty.txt` into a pandas dataframe. Extract the `Brth15to17` and `PovPct` columns into separate numpy arrays.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Define tensorflow placeholders for the matrix of independent variables and the vector of target values. Allow for a variable number of data points and features.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Build a Tensorflow graph that outputs the solution to the linear regression problem using the normal equation.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. Use your Tensorflow graph to regress `Brth15to17` against `PovPct`; that is, predict `Brth15to17` from `PovPct`. Print out the linear regression model coefficients, and plot the data and the linear regression model.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5. Use the same Tensorflow graph to regress `Brth15to17` against `PovPct` and `ViolCrime`. Print the model parameters.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: SVN dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the SVHN dataset to build a neural network classifier. The remaining exercises in this notebook will prepare the dataset ready for building the model. Take a look at the dataset here: http://ufldl.stanford.edu/housenumbers/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6. Download the SVHN dataset from the above URL. The data consists of files `train_32x32.mat`, `test_32x32.mat` and `extra_32x32.mat`. We will only use the first two of these files.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**7. Explore the dataset: find out how many examples there are in the training and test sets, what the dimensions of the arrays are, and what the labels are for the set of images. If necessary, reorganise the image arrays so they are in the standard format `(num_examples, height, width, num_channels)`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**8. Make a 3x3 subplot to visualise randomly selected images from the dataset, together with their labels.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**9. In order to simplify the network model, we will convert the dataset images to grayscale. To do this, take the average value across the three RBG channels for each image. Finally, normalise the data by ensuring the range of values lies between $-1$ and $1$. The final array should still be a 4D array, with the last dimension equal to 1.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**10. Make another 3x3 subplots figure with random examples from the dataset and their labels, this time using the grayscale converted images you have made.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**11. We also need to process the labels ready for training. Convert the labels to _one hot vectors_, so each label will be a vector of 10 entries, where all entries are 0 except for one which is 1, corresponding to the correct label. Note that 10 is a label, and we will encode this into the first entry, so for example: $$[10] -> [1, 0, 0, 0, 0, 0, 0, 0, 0, 0]$$ $$[2] -> [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]$$**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**12. Save the numpy grayscale image arrays and labels for training and test sets for later use when we will use them to train our network classifier.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
